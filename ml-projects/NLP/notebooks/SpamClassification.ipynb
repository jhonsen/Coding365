{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>org.apache.opennlp</groupId>\n",
    "    <artifactId>opennlp-tools</artifactId>\n",
    "    <version>1.9.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.BufferedReader;\n",
    "import java.io.BufferedWriter;\n",
    "import java.io.File;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.FileNotFoundException;\n",
    "import java.io.FileReader;\n",
    "import java.io.FileWriter;\n",
    "import java.io.IOException;\n",
    "import java.io.InputStream;\n",
    "import java.nio.charset.StandardCharsets;\n",
    "import java.util.ArrayList;\n",
    "import opennlp.tools.doccat.DoccatModel;\n",
    "import opennlp.tools.doccat.DocumentCategorizerME;\n",
    "import opennlp.tools.doccat.DocumentSample;\n",
    "import opennlp.tools.doccat.DocumentSampleStream;\n",
    "import opennlp.tools.util.ObjectStream;\n",
    "import opennlp.tools.util.InputStreamFactory;\n",
    "import opennlp.tools.util.PlainTextByLineStream;\n",
    "import opennlp.tools.util.MarkableFileInputStreamFactory;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files can't be found\n"
     ]
    }
   ],
   "source": [
    "ArrayList<String> testList = new ArrayList();\n",
    "try (BufferedWriter spamBufferedWriter = new BufferedWriter(\n",
    "        new FileWriter(new File(\"../data/spamtraining.train\")))) {\n",
    "    \n",
    "    String rootDirectoryName = \"../data/lingspam_public/stop\";\n",
    "    File rootDirectory = new File(rootDirectoryName);\n",
    "    for (String directoryName : rootDirectory.list()) {\n",
    "        File file = new File(rootDirectoryName + \"/\" + directoryName);\n",
    "        \n",
    "        // Open one file at a time\n",
    "        String fileNames[] = file.list();\n",
    "        if (fileNames != null) {\n",
    "            for (String fileName : fileNames) {\n",
    "                String filePath = rootDirectoryName + \"/\" + directoryName + \n",
    "                    \"/\" + fileName;\n",
    "                StringBuilder lineStringBuilder = new StringBuilder();\n",
    "                \n",
    "                // OpenNLP requires a SPAM or HAM header, followed by single line text \n",
    "                BufferedReader br = new BufferedReader(new FileReader(new File(filePath)));\n",
    "                String line = null;\n",
    "                if (fileName.contains(\"spms\")) {\n",
    "                    lineStringBuilder.append(\"spam\\t\");\n",
    "                } else {\n",
    "                    lineStringBuilder.append(\"ham\\t\");\n",
    "                }\n",
    "                while ((line = br.readLine()) != null) {\n",
    "                    lineStringBuilder.append(line);\n",
    "                }\n",
    "                if (directoryName.equals(\"part10\")) {\n",
    "                    testList.add(lineStringBuilder.toString());\n",
    "                } else {\n",
    "                    spamBufferedWriter.write(lineStringBuilder.toString() + \"\\n\");\n",
    "                }\n",
    "                lineStringBuilder.setLength(0);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "} catch (IOException ex) {\n",
    "    // Handle exceptions\n",
    "    System.out.println(\"Files can't be found\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompilationException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    ObjectStream<String> objectStream = \u001b[0m\u001b[1m\u001b[30m\u001b[41mnew PlainTextByLineStream(dataInputStream, StandardCharsets.UTF_8)\u001b[0m\u001b[1m\u001b[30m;\u001b[0m",
      "\u001b[1m\u001b[31mno suitable constructor found for PlainTextByLineStream(java.io.InputStream,java.nio.charset.Charset)\u001b[0m",
      "\u001b[1m\u001b[31m    constructor opennlp.tools.util.PlainTextByLineStream.PlainTextByLineStream(opennlp.tools.util.InputStreamFactory,java.lang.String) is not applicable\u001b[0m",
      "\u001b[1m\u001b[31m      (argument mismatch; java.io.InputStream cannot be converted to opennlp.tools.util.InputStreamFactory)\u001b[0m",
      "\u001b[1m\u001b[31m    constructor opennlp.tools.util.PlainTextByLineStream.PlainTextByLineStream(opennlp.tools.util.InputStreamFactory,java.nio.charset.Charset) is not applicable\u001b[0m",
      "\u001b[1m\u001b[31m      (argument mismatch; java.io.InputStream cannot be converted to opennlp.tools.util.InputStreamFactory)\u001b[0m",
      "",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    DoccatModel documentCategorizationModel = \u001b[0m\u001b[1m\u001b[30m\u001b[41mDocumentCategorizerME.train\u001b[0m\u001b[1m\u001b[30m(\"en\", documentSampleStream);\u001b[0m",
      "\u001b[1m\u001b[31mmethod train in class opennlp.tools.doccat.DocumentCategorizerME cannot be applied to given types;\u001b[0m",
      "\u001b[1m\u001b[31m  required: java.lang.String,opennlp.tools.util.ObjectStream<opennlp.tools.doccat.DocumentSample>,opennlp.tools.util.TrainingParameters,opennlp.tools.doccat.DoccatFactory\u001b[0m",
      "\u001b[1m\u001b[31m  found:    java.lang.String,opennlp.tools.util.ObjectStream<opennlp.tools.doccat.DocumentSample>\u001b[0m",
      "\u001b[1m\u001b[31m  reason: actual and formal argument lists differ in length\u001b[0m",
      "",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        double[] probabilities = documentCategorizer.categorize(\u001b[0m\u001b[1m\u001b[30m\u001b[41mtestItem\u001b[0m\u001b[1m\u001b[30m);\u001b[0m",
      "\u001b[1m\u001b[31mincompatible types: java.lang.String cannot be converted to java.lang.String[]\u001b[0m",
      ""
     ]
    }
   ],
   "source": [
    "// Test the model using the test data in testListArrayList\n",
    "try (InputStream dataInputStream = new FileInputStream(\"../data/spamtraining.train\")) {\n",
    "    // Create input stream for training data\n",
    "    ObjectStream<String> objectStream = new PlainTextByLineStream(dataInputStream, StandardCharsets.UTF_8);\n",
    "    ObjectStream<DocumentSample> documentSampleStream = new DocumentSampleStream(objectStream);\n",
    "\n",
    "    DoccatModel documentCategorizationModel = DocumentCategorizerME.train(\"en\", documentSampleStream);\n",
    "    DocumentCategorizerME documentCategorizer = new DocumentCategorizerME(documentCategorizationModel);\n",
    "    for (String testItem : testList) {\n",
    "        double[] probabilities = documentCategorizer.categorize(testItem);\n",
    "        String bestCategory = documentCategorizer.getBestCategory(probabilities);\n",
    "        System.out.println(\"The best fit for: [\" + testItem.subSequence(0, 32) + \"...] is: \" + bestCategory);\n",
    "    }\n",
    "} catch (FileNotFoundException ex) {\n",
    "    // Handle exceptions\n",
    "} catch (IOException ex) {\n",
    "    // Handle exceptions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "14.0.1+7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
