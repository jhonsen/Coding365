{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>org.apache.opennlp</groupId>\n",
    "    <artifactId>opennlp-tools</artifactId>\n",
    "    <version>1.9.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.BufferedReader;\n",
    "import java.io.BufferedWriter;\n",
    "import java.io.File;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.FileNotFoundException;\n",
    "import java.io.FileReader;\n",
    "import java.io.FileWriter;\n",
    "import java.io.IOException;\n",
    "import java.io.InputStream;\n",
    "import java.nio.charset.StandardCharsets;\n",
    "import java.util.ArrayList;\n",
    "import opennlp.tools.doccat.DoccatModel;\n",
    "import opennlp.tools.doccat.DocumentCategorizerME;\n",
    "import opennlp.tools.doccat.DocumentSample;\n",
    "import opennlp.tools.doccat.DocumentSampleStream;\n",
    "import opennlp.tools.doccat.DoccatFactory;\n",
    "import opennlp.tools.util.TrainingParameters;\n",
    "import opennlp.tools.util.ObjectStream;\n",
    "import opennlp.tools.util.InputStreamFactory;\n",
    "import opennlp.tools.util.PlainTextByLineStream;\n",
    "import opennlp.tools.util.MarkableFileInputStreamFactory;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrayList<String> testList = new ArrayList();\n",
    "try (BufferedWriter spamBufferedWriter = new BufferedWriter(\n",
    "        new FileWriter(new File(\"../data/spamtraining.train\")))) {\n",
    "    \n",
    "        String rootDirectoryName = \"../data/lingspam_public/stop\";\n",
    "    File rootDirectory = new File(rootDirectoryName);\n",
    "    for (String directoryName : rootDirectory.list()) {\n",
    "        File file = new File(rootDirectoryName + \"/\" + directoryName);\n",
    "        \n",
    "//         // Open one file at a time\n",
    "        String fileNames[] = file.list();\n",
    "        if (fileNames != null) {\n",
    "            for (String fileName : fileNames) {\n",
    "                    if (!fileName.equals(\".ipynb_checkpoints\")){\n",
    "                    String filePath = rootDirectoryName + \"/\" + directoryName + \n",
    "                        \"/\" + fileName;\n",
    "                    StringBuilder lineStringBuilder = new StringBuilder();\n",
    "\n",
    "                    // OpenNLP requires a SPAM or HAM header, followed by single line text \n",
    "                    BufferedReader br = new BufferedReader(new FileReader(new File(filePath)));\n",
    "                    String line = null;\n",
    "                    if (fileName.contains(\"spms\")) {\n",
    "                        lineStringBuilder.append(\"spam\\t\");\n",
    "                    } else {\n",
    "                        lineStringBuilder.append(\"ham\\t\");\n",
    "                    }\n",
    "                    while ((line = br.readLine()) != null) {\n",
    "                        lineStringBuilder.append(line);\n",
    "                    }\n",
    "                    if (directoryName.equals(\"part10\")) {\n",
    "                        testList.add(lineStringBuilder.toString());\n",
    "                    } else {\n",
    "                        spamBufferedWriter.write(lineStringBuilder.toString() + \"\\n\");\n",
    "                    }\n",
    "                    lineStringBuilder.setLength(0);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "} catch (IOException ex) {\n",
    "    // Handle exceptions\n",
    "    System.out.println(\"Files can't be found\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing events with TwoPass using cutoff of 5\n",
      "\n",
      "\tComputing event counts...  done. 867 events\n",
      "\tIndexing...  done.\n",
      "Sorting and merging events... done. Reduced 867 events to 865.\n",
      "Done indexing in 0.33 s.\n",
      "Incorporating indexed data for training...  \n",
      "done.\n",
      "\tNumber of Event Tokens: 865\n",
      "\t    Number of Outcomes: 2\n",
      "\t  Number of Predicates: 6589\n",
      "...done.\n",
      "Computing model parameters ...\n",
      "Performing 100 iterations.\n",
      "  1:  ... loglikelihood=-600.9586055454669\t0.8339100346020761\n",
      "  2:  ... loglikelihood=-563.4439818431681\t0.8673587081891581\n",
      "  3:  ... loglikelihood=-534.494142891077\t0.8846597462514417\n",
      "  4:  ... loglikelihood=-510.9776348762483\t0.895040369088812\n",
      "  5:  ... loglikelihood=-491.1479986818805\t0.9100346020761245\n",
      "  6:  ... loglikelihood=-473.99868163524843\t0.9192618223760092\n",
      "  7:  ... loglikelihood=-458.8998105080639\t0.9250288350634371\n",
      "  8:  ... loglikelihood=-445.4270915060151\t0.9296424452133795\n",
      "  9:  ... loglikelihood=-433.2783196776066\t0.9377162629757786\n",
      " 10:  ... loglikelihood=-422.2292073970415\t0.9434832756632064\n",
      " 11:  ... loglikelihood=-412.10806859570914\t0.9480968858131488\n",
      " 12:  ... loglikelihood=-402.78028925787487\t0.9492502883506344\n",
      " 13:  ... loglikelihood=-394.138265542944\t0.9527104959630911\n",
      " 14:  ... loglikelihood=-386.0945972975893\t0.9550173010380623\n",
      " 15:  ... loglikelihood=-378.57732423368475\t0.9584775086505191\n",
      " 16:  ... loglikelihood=-371.5264991496164\t0.9619377162629758\n",
      " 17:  ... loglikelihood=-364.8916665528318\t0.9653979238754326\n",
      " 18:  ... loglikelihood=-358.6299716036395\t0.9665513264129181\n",
      " 19:  ... loglikelihood=-352.70471813254176\t0.9677047289504037\n",
      " 20:  ... loglikelihood=-347.08425298160876\t0.9688581314878892\n",
      " 21:  ... loglikelihood=-341.7410915924844\t0.9700115340253749\n",
      " 22:  ... loglikelihood=-336.6512246872032\t0.9700115340253749\n",
      " 23:  ... loglikelihood=-331.79356275884675\t0.9700115340253749\n",
      " 24:  ... loglikelihood=-327.1494867375984\t0.9700115340253749\n",
      " 25:  ... loglikelihood=-322.7024813827388\t0.972318339100346\n",
      " 26:  ... loglikelihood=-318.43783379367795\t0.972318339100346\n",
      " 27:  ... loglikelihood=-314.34238366366213\t0.972318339100346\n",
      " 28:  ... loglikelihood=-310.4043150035031\t0.972318339100346\n",
      " 29:  ... loglikelihood=-306.61298136735707\t0.9734717416378316\n",
      " 30:  ... loglikelihood=-302.95875834315433\t0.9734717416378316\n",
      " 31:  ... loglikelihood=-299.4329183832747\t0.9746251441753172\n",
      " 32:  ... loglikelihood=-296.02752405683157\t0.9757785467128027\n",
      " 33:  ... loglikelihood=-292.7353365823944\t0.9769319492502884\n",
      " 34:  ... loglikelihood=-289.5497371058076\t0.9792387543252595\n",
      " 35:  ... loglikelihood=-286.4646586637584\t0.9792387543252595\n",
      " 36:  ... loglikelihood=-283.4745271502485\t0.9803921568627451\n",
      " 37:  ... loglikelihood=-280.57420990313017\t0.9803921568627451\n",
      " 38:  ... loglikelihood=-277.758970768323\t0.9803921568627451\n",
      " 39:  ... loglikelihood=-275.02443069330525\t0.9815455594002307\n",
      " 40:  ... loglikelihood=-272.3665330587774\t0.9815455594002307\n",
      " 41:  ... loglikelihood=-269.78151308566146\t0.9815455594002307\n",
      " 42:  ... loglikelihood=-267.2658707597403\t0.9815455594002307\n",
      " 43:  ... loglikelihood=-264.81634680278705\t0.9815455594002307\n",
      " 44:  ... loglikelihood=-262.42990129063105\t0.9815455594002307\n",
      " 45:  ... loglikelihood=-260.10369457809344\t0.9815455594002307\n",
      " 46:  ... loglikelihood=-257.8350702403255\t0.9826989619377162\n",
      " 47:  ... loglikelihood=-255.6215397816405\t0.9826989619377162\n",
      " 48:  ... loglikelihood=-253.46076889783217\t0.9826989619377162\n",
      " 49:  ... loglikelihood=-251.3505651074478\t0.9826989619377162\n",
      " 50:  ... loglikelihood=-249.28886659239652\t0.9826989619377162\n",
      " 51:  ... loglikelihood=-247.27373210946274\t0.9826989619377162\n",
      " 52:  ... loglikelihood=-245.3033318523356\t0.9826989619377162\n",
      " 53:  ... loglikelihood=-243.3759391591556\t0.9826989619377162\n",
      " 54:  ... loglikelihood=-241.48992297382932\t0.9826989619377162\n",
      " 55:  ... loglikelihood=-239.6437409806771\t0.9826989619377162\n",
      " 56:  ... loglikelihood=-237.8359333417969\t0.9826989619377162\n",
      " 57:  ... loglikelihood=-236.06511697495625\t0.9826989619377162\n",
      " 58:  ... loglikelihood=-234.32998031716713\t0.9826989619377162\n",
      " 59:  ... loglikelihood=-232.62927852544487\t0.9838523644752019\n",
      " 60:  ... loglikelihood=-230.9618290717863\t0.9850057670126874\n",
      " 61:  ... loglikelihood=-229.3265076942461\t0.986159169550173\n",
      " 62:  ... loglikelihood=-227.72224467018674\t0.986159169550173\n",
      " 63:  ... loglikelihood=-226.1480213814939\t0.986159169550173\n",
      " 64:  ... loglikelihood=-224.60286714479287\t0.986159169550173\n",
      " 65:  ... loglikelihood=-223.0858562825351\t0.986159169550173\n",
      " 66:  ... loglikelihood=-221.59610541338645\t0.986159169550173\n",
      " 67:  ... loglikelihood=-220.1327709425082\t0.9884659746251442\n",
      " 68:  ... loglikelihood=-218.6950467343522\t0.9884659746251442\n",
      " 69:  ... loglikelihood=-217.2821619522714\t0.9896193771626297\n",
      " 70:  ... loglikelihood=-215.89337905085108\t0.9907727797001153\n",
      " 71:  ... loglikelihood=-214.52799190818894\t0.9907727797001153\n",
      " 72:  ... loglikelihood=-213.18532408661096\t0.9907727797001153\n",
      " 73:  ... loglikelihood=-211.86472721138506\t0.9907727797001153\n",
      " 74:  ... loglikelihood=-210.56557945797792\t0.9919261822376009\n",
      " 75:  ... loglikelihood=-209.28728413926459\t0.9919261822376009\n",
      " 76:  ... loglikelihood=-208.0292683848894\t0.9919261822376009\n",
      " 77:  ... loglikelihood=-206.79098190568112\t0.9919261822376009\n",
      " 78:  ... loglikelihood=-205.57189583663293\t0.9919261822376009\n",
      " 79:  ... loglikelihood=-204.37150165256983\t0.9919261822376009\n",
      " 80:  ... loglikelihood=-203.18931015108157\t0.9919261822376009\n",
      " 81:  ... loglikelihood=-202.02485049781131\t0.9919261822376009\n",
      " 82:  ... loglikelihood=-200.87766932956916\t0.9919261822376009\n",
      " 83:  ... loglikelihood=-199.74732991114067\t0.9919261822376009\n",
      " 84:  ... loglikelihood=-198.63341134198615\t0.9919261822376009\n",
      " 85:  ... loglikelihood=-197.53550780935066\t0.9919261822376009\n",
      " 86:  ... loglikelihood=-196.45322788457034\t0.9919261822376009\n",
      " 87:  ... loglikelihood=-195.3861938596238\t0.9930795847750865\n",
      " 88:  ... loglikelihood=-194.33404112121625\t0.9930795847750865\n",
      " 89:  ... loglikelihood=-193.29641755988217\t0.9930795847750865\n",
      " 90:  ... loglikelihood=-192.2729830117899\t0.9930795847750865\n",
      " 91:  ... loglikelihood=-191.26340873112142\t0.9930795847750865\n",
      " 92:  ... loglikelihood=-190.26737689103305\t0.9930795847750865\n",
      " 93:  ... loglikelihood=-189.28458011138554\t0.9930795847750865\n",
      " 94:  ... loglikelihood=-188.3147210115332\t0.9930795847750865\n",
      " 95:  ... loglikelihood=-187.35751178660465\t0.9930795847750865\n",
      " 96:  ... loglikelihood=-186.41267380583056\t0.9930795847750865\n",
      " 97:  ... loglikelihood=-185.47993723153928\t0.9930795847750865\n",
      " 98:  ... loglikelihood=-184.55904065758511\t0.9930795847750865\n",
      " 99:  ... loglikelihood=-183.64973076603204\t0.9930795847750865\n",
      "100:  ... loglikelihood=-182.75176200099622\t0.9930795847750865\n",
      "The best fit for: [ham\tSubject: sound patterns spon...] is: ham\n",
      "The best fit for: [ham\tSubject: atelier des doctora...] is: ham\n",
      "The best fit for: [ham\tSubject: journal - - informa...] is: ham\n",
      "The best fit for: [ham\tSubject: wholes partswholes ...] is: ham\n",
      "The best fit for: [ham\tSubject: conference research...] is: ham\n",
      "The best fit for: [ham\tSubject: bilingualism2nd int...] is: ham\n",
      "The best fit for: [ham\tSubject: symposium meaning ,...] is: ham\n",
      "The best fit for: [ham\tSubject: console 7 : cfp- - ...] is: ham\n",
      "The best fit for: [ham\tSubject: ecdl98 - final call...] is: ham\n",
      "The best fit for: [ham\tSubject: corpus - based stat...] is: ham\n",
      "The best fit for: [ham\tSubject: lrec workshop , pre...] is: ham\n",
      "The best fit for: [ham\tSubject: hokan - penutian co...] is: ham\n",
      "The best fit for: [ham\tSubject: franklin clipper ( ...] is: ham\n",
      "The best fit for: [ham\tSubject: 3rd emnlp cfpcall p...] is: ham\n",
      "The best fit for: [ham\tSubject: 6th manchester phon...] is: ham\n",
      "The best fit for: [ham\tSubject: prolamat 98 : call ...] is: ham\n",
      "The best fit for: [ham\tSubject: minority languages ...] is: ham\n",
      "The best fit for: [ham\tSubject: yale working papers...] is: ham\n",
      "The best fit for: [ham\tSubject: nlp + ia ' 98 deadl...] is: ham\n",
      "The best fit for: [ham\tSubject: tag + 1998* deadlin...] is: ham\n",
      "The best fit for: [ham\tSubject: phonologycertamen p...] is: ham\n",
      "The best fit for: [ham\tSubject: icslp abstracts due...] is: ham\n",
      "The best fit for: [ham\tSubject: \" language resource...] is: ham\n",
      "The best fit for: [ham\tSubject: logic course intern...] is: ham\n",
      "The best fit for: [ham\tSubject: ellipsis conjunctio...] is: ham\n",
      "The best fit for: [ham\tSubject: non - lexical seman...] is: ham\n",
      "The best fit for: [ham\tSubject: language cognitive ...] is: ham\n",
      "The best fit for: [ham\tSubject: history linguistic ...] is: ham\n",
      "The best fit for: [ham\tSubject: teaching linguistic...] is: ham\n",
      "The best fit for: [ham\tSubject: colloque : plurilin...] is: ham\n",
      "The best fit for: [ham\tSubject: sigphon98 workshop ...] is: ham\n",
      "The best fit for: [ham\tSubject: special issue machi...] is: ham\n",
      "The best fit for: [ham\tSubject: reflections grammat...] is: ham\n",
      "The best fit for: [ham\tSubject: germanic generative...] is: ham\n",
      "The best fit for: [ham\tSubject: generative approach...] is: ham\n",
      "The best fit for: [ham\tSubject: multimedia indexing...] is: ham\n",
      "The best fit for: [ham\tSubject: knowledge language ...] is: ham\n",
      "The best fit for: [ham\tSubject: sla conference pari...] is: ham\n",
      "The best fit for: [ham\tSubject: history phonetic sc...] is: ham\n",
      "The best fit for: [ham\tSubject: fsmnlp ' 98 student...] is: ham\n",
      "The best fit for: [ham\tSubject: kornfilt : turkishj...] is: ham\n",
      "The best fit for: [ham\tSubject: review perez - lero...] is: ham\n",
      "The best fit for: [ham\tSubject: evaluation parsing ...] is: ham\n",
      "The best fit for: [ham\tSubject: language resources ...] is: ham\n",
      "The best fit for: [ham\tSubject: tsd98 - - 3rd call ...] is: ham\n",
      "The best fit for: [ham\tSubject: call : nystesol app...] is: ham\n",
      "The best fit for: [ham\tSubject: creating sense* * *...] is: ham\n",
      "The best fit for: [ham\tSubject: nlp + ia ' 98 aspec...] is: ham\n",
      "The best fit for: [ham\tSubject: conference catalan ...] is: ham\n",
      "The best fit for: [ham\tSubject: translationtranslat...] is: ham\n",
      "The best fit for: [ham\tSubject: 8th seals , kuala l...] is: ham\n",
      "The best fit for: [ham\tSubject: icgi-98- - - - - - ...] is: ham\n",
      "The best fit for: [ham\tSubject: acm sac ' 99 - trac...] is: ham\n",
      "The best fit for: [ham\tSubject: vilem mathesius lec...] is: ham\n",
      "The best fit for: [ham\tSubject: 3rd annual interdis...] is: ham\n",
      "The best fit for: [ham\tSubject: claw 98 programclaw...] is: ham\n",
      "The best fit for: [ham\tSubject: cfp : wecol ' 98cal...] is: ham\n",
      "The best fit for: [ham\tSubject: asia - pacific lang...] is: ham\n",
      "The best fit for: [ham\tSubject: xth conference nord...] is: ham\n",
      "The best fit for: [ham\tSubject: augias , linguistic...] is: ham\n",
      "The best fit for: [ham\tSubject: sociolinguisticsmed...] is: ham\n",
      "The best fit for: [ham\tSubject: computers linguisti...] is: ham\n",
      "The best fit for: [ham\tSubject: anthropological lin...] is: ham\n",
      "The best fit for: [ham\tSubject: cfp : icsnl ' 98ann...] is: ham\n",
      "The best fit for: [ham\tSubject: foreign language cu...] is: ham\n",
      "The best fit for: [ham\tSubject: technology & foreig...] is: ham\n",
      "The best fit for: [ham\tSubject: book : dialects var...] is: ham\n",
      "The best fit for: [ham\tSubject: books : sociolingui...] is: ham\n",
      "The best fit for: [ham\tSubject: books : historical ...] is: ham\n",
      "The best fit for: [ham\tSubject: books : language in...] is: ham\n",
      "The best fit for: [ham\tSubject: going romance 1998c...] is: ham\n",
      "The best fit for: [ham\tSubject: nels 29 - - call pa...] is: ham\n",
      "The best fit for: [ham\tSubject: 2nd language acquis...] is: ham\n",
      "The best fit for: [ham\tSubject: lexical semantics s...] is: ham\n",
      "The best fit for: [ham\tSubject: coling-acl ' 98 com...] is: ham\n",
      "The best fit for: [ham\tSubject: distributing access...] is: ham\n",
      "The best fit for: [ham\tSubject: optimality theoryop...] is: ham\n",
      "The best fit for: [ham\tSubject: syntax semantics te...] is: ham\n",
      "The best fit for: [ham\tSubject: tromsoe conference ...] is: ham\n",
      "The best fit for: [ham\tSubject: iatl 14israel assoc...] is: ham\n",
      "The best fit for: [ham\tSubject: dependency - based ...] is: ham\n",
      "The best fit for: [ham\tSubject: beyond boundaries i...] is: ham\n",
      "The best fit for: [ham\tSubject: international summe...] is: ham\n",
      "The best fit for: [ham\tSubject: lagb autumn meeting...] is: ham\n",
      "The best fit for: [ham\tSubject: workshop embodied c...] is: ham\n",
      "The best fit for: [ham\tSubject: fourth mid-continen...] is: ham\n",
      "The best fit for: [ham\tSubject: document designdece...] is: ham\n",
      "The best fit for: [ham\tSubject: gala ' 97 proceedin...] is: ham\n",
      "The best fit for: [ham\tSubject: meeting noticefourt...] is: ham\n",
      "The best fit for: [ham\tSubject: australian linguist...] is: ham\n",
      "The best fit for: [ham\tSubject: scil 10call papers ...] is: ham\n",
      "The best fit for: [ham\tSubject: conference announce...] is: ham\n",
      "The best fit for: [ham\tSubject: sampson : educating...] is: ham\n",
      "The best fit for: [ham\tSubject: usc ea syntax works...] is: ham\n",
      "The best fit for: [ham\tSubject: semcom : webnet jou...] is: ham\n",
      "The best fit for: [ham\tSubject: conference announce...] is: ham\n",
      "The best fit for: [ham\tSubject: survey studysurvey ...] is: ham\n",
      "The best fit for: [ham\tSubject: computationally - i...] is: ham\n",
      "The best fit for: [ham\tSubject: sociolinguisticswom...] is: ham\n",
      "The best fit for: [ham\tSubject: languages world , i...] is: ham\n",
      "The best fit for: [ham\tSubject: phonologyunderstand...] is: ham\n",
      "The best fit for: [ham\tSubject: pragmaticsunderstan...] is: ham\n",
      "The best fit for: [ham\tSubject: syntaxunderstanding...] is: ham\n",
      "The best fit for: [ham\tSubject: labphon6 registrati...] is: ham\n",
      "The best fit for: [ham\tSubject: special stream cogn...] is: ham\n",
      "The best fit for: [ham\tSubject: wml : deadline exte...] is: ham\n",
      "The best fit for: [ham\tSubject: corrected conferenc...] is: ham\n",
      "The best fit for: [ham\tSubject: armenian linguistic...] is: ham\n",
      "The best fit for: [ham\tSubject: xi int . selim conf...] is: ham\n",
      "The best fit for: [ham\tSubject: final programme wor...] is: ham\n",
      "The best fit for: [ham\tSubject: making sense langua...] is: ham\n",
      "The best fit for: [ham\tSubject: lassocall papers la...] is: ham\n",
      "The best fit for: [ham\tSubject: mt special issue sl...] is: ham\n",
      "The best fit for: [ham\tSubject: korean linguistics ...] is: ham\n",
      "The best fit for: [ham\tSubject: conference maintena...] is: ham\n",
      "The best fit for: [ham\tSubject: csdl - 4preliminary...] is: ham\n",
      "The best fit for: [ham\tSubject: program & info : wo...] is: ham\n",
      "The best fit for: [ham\tSubject: journees de rochebr...] is: ham\n",
      "The best fit for: [ham\tSubject: table contentsinsti...] is: ham\n",
      "The best fit for: [ham\tSubject: 1998 nic symposium1...] is: ham\n",
      "The best fit for: [ham\tSubject: sle 98 st . andrews...] is: ham\n",
      "The best fit for: [ham\tSubject: aiml ' 98 : final c...] is: ham\n",
      "The best fit for: [ham\tSubject: workshop annoncemen...] is: ham\n",
      "The best fit for: [ham\tSubject: conferrence ' minor...] is: ham\n",
      "The best fit for: [ham\tSubject: available review : ...] is: ham\n",
      "The best fit for: [ham\tSubject: amsterdam series ch...] is: ham\n",
      "The best fit for: [ham\tSubject: books syntax & morp...] is: ham\n",
      "The best fit for: [ham\tSubject: books phonetics & p...] is: ham\n",
      "The best fit for: [ham\tSubject: books sociolinguist...] is: ham\n",
      "The best fit for: [ham\tSubject: confs : scil 10 - l...] is: ham\n",
      "The best fit for: [ham\tSubject: tag + workshop regi...] is: ham\n",
      "The best fit for: [ham\tSubject: bisca-98bisca-98 - ...] is: ham\n",
      "The best fit for: [ham\tSubject: wholes partswholes ...] is: ham\n",
      "The best fit for: [ham\tSubject: amta ' 98* * deadli...] is: ham\n",
      "The best fit for: [ham\tSubject: aaal - - colloquium...] is: ham\n",
      "The best fit for: [ham\tSubject: adcs ' 98following ...] is: ham\n",
      "The best fit for: [ham\tSubject: 9th intl congress l...] is: ham\n",
      "The best fit for: [ham\tSubject: call papers - pragm...] is: ham\n",
      "The best fit for: [ham\tSubject: germanic romance mo...] is: ham\n",
      "The best fit for: [ham\tSubject: our knowledge human...] is: ham\n",
      "The best fit for: [ham\tSubject: theory predicatesth...] is: ham\n",
      "The best fit for: [ham\tSubject: diachronica xv : 1s...] is: ham\n",
      "The best fit for: [ham\tSubject: maryland working pa...] is: ham\n",
      "The best fit for: [ham\tSubject: chicago phonetics p...] is: ham\n",
      "The best fit for: [ham\tSubject: workshop announceme...] is: ham\n",
      "The best fit for: [ham\tSubject: understanding phono...] is: ham\n",
      "The best fit for: [ham\tSubject: understanding pragm...] is: ham\n",
      "The best fit for: [ham\tSubject: understanding synta...] is: ham\n",
      "The best fit for: [ham\tSubject: workshop morphologi...] is: ham\n",
      "The best fit for: [ham\tSubject: review : watt , pho...] is: ham\n",
      "The best fit for: [ham\tSubject: euralex ' 98 - keyn...] is: ham\n",
      "The best fit for: [ham\tSubject: computerm ' 98 work...] is: ham\n",
      "The best fit for: [ham\tSubject: 2nd ws interlinguas...] is: ham\n",
      "The best fit for: [ham\tSubject: esslli-99 , final c...] is: ham\n",
      "The best fit for: [ham\tSubject: endangered language...] is: ham\n",
      "The best fit for: [ham\tSubject: afro - asiatic lang...] is: ham\n",
      "The best fit for: [ham\tSubject: 8th international c...] is: ham\n",
      "The best fit for: [ham\tSubject: special issue jetai...] is: ham\n",
      "The best fit for: [ham\tSubject: acm sigir98 worksho...] is: ham\n",
      "The best fit for: [ham\tSubject: 10th icehl10th inte...] is: ham\n",
      "The best fit for: [ham\tSubject: available review : ...] is: ham\n",
      "The best fit for: [ham\tSubject: coling / acl ' 98 w...] is: ham\n",
      "The best fit for: [ham\tSubject: typology theorycall...] is: ham\n",
      "The best fit for: [ham\tSubject: available review : ...] is: ham\n",
      "The best fit for: [ham\tSubject: 6th dgfs - summer s...] is: ham\n",
      "The best fit for: [ham\tSubject: 2nd workshop interl...] is: ham\n",
      "The best fit for: [ham\tSubject: icgi-98 call papers...] is: ham\n",
      "The best fit for: [ham\tSubject: conf : computerm wo...] is: ham\n",
      "The best fit for: [ham\tSubject: linguistics journal...] is: ham\n",
      "The best fit for: [ham\tSubject: books : bilingualis...] is: ham\n",
      "The best fit for: [ham\tSubject: afro - asiatic lang...] is: ham\n",
      "The best fit for: [ham\tSubject: third international...] is: ham\n",
      "The best fit for: [ham\tSubject: 1999 genetic evolut...] is: ham\n",
      "The best fit for: [ham\tSubject: anglo - american st...] is: ham\n",
      "The best fit for: [ham\tSubject: semanticsbring atte...] is: ham\n",
      "The best fit for: [ham\tSubject: books : translation...] is: ham\n",
      "The best fit for: [ham\tSubject: inversion romanceca...] is: ham\n",
      "The best fit for: [ham\tSubject: lrec workshop annou...] is: ham\n",
      "The best fit for: [ham\tSubject: kbcs-98 call papers...] is: ham\n",
      "The best fit for: [ham\tSubject: using acquiring lex...] is: ham\n",
      "The best fit for: [ham\tSubject: ld ' 98 - call part...] is: ham\n",
      "The best fit for: [ham\tSubject: intelligent industr...] is: ham\n",
      "The best fit for: [ham\tSubject: canadian assoc . im...] is: ham\n",
      "The best fit for: [ham\tSubject: program joint conf ...] is: ham\n",
      "The best fit for: [ham\tSubject: books : generative ...] is: ham\n",
      "The best fit for: [ham\tSubject: books : pragmatics ...] is: ham\n",
      "The best fit for: [ham\tSubject: consciousnessjohn b...] is: ham\n",
      "The best fit for: [ham\tSubject: meaning change - me...] is: ham\n",
      "The best fit for: [ham\tSubject: transcription conti...] is: ham\n",
      "The best fit for: [ham\tSubject: conference ' lexico...] is: ham\n",
      "The best fit for: [ham\tSubject: correction issue 9 ...] is: ham\n",
      "The best fit for: [ham\tSubject: review massaro 1998...] is: ham\n",
      "The best fit for: [ham\tSubject: 14th comparative ge...] is: ham\n",
      "The best fit for: [ham\tSubject: nels 29 - - final c...] is: ham\n",
      "The best fit for: [ham\tSubject: semitic languages w...] is: ham\n",
      "The best fit for: [ham\tSubject: computers humanitie...] is: ham\n",
      "The best fit for: [ham\tSubject: prepositions worksh...] is: ham\n",
      "The best fit for: [ham\tSubject: phonetics , phonolo...] is: ham\n",
      "The best fit for: [ham\tSubject: sociolinguisticssoc...] is: ham\n",
      "The best fit for: [ham\tSubject: morphology syntaxde...] is: ham\n",
      "The best fit for: [ham\tSubject: semanticsdynamics f...] is: ham\n",
      "The best fit for: [ham\tSubject: cognitive linguisti...] is: ham\n",
      "The best fit for: [ham\tSubject: historical linguist...] is: ham\n",
      "The best fit for: [ham\tSubject: relevance theory wo...] is: ham\n",
      "The best fit for: [ham\tSubject: honored two keynote...] is: ham\n",
      "The best fit for: [ham\tSubject: corrected announcem...] is: ham\n",
      "The best fit for: [ham\tSubject: lexical functional ...] is: ham\n",
      "The best fit for: [ham\tSubject: icslp ' 98call pape...] is: ham\n",
      "The best fit for: [ham\tSubject: avail review : phon...] is: ham\n",
      "The best fit for: [ham\tSubject: sociolinguisticsend...] is: ham\n",
      "The best fit for: [ham\tSubject: language educationl...] is: ham\n",
      "The best fit for: [ham\tSubject: typologybring atten...] is: ham\n",
      "The best fit for: [ham\tSubject: uci dissertations l...] is: ham\n",
      "The best fit for: [ham\tSubject: encyclopediacambrid...] is: ham\n",
      "The best fit for: [ham\tSubject: series : studies co...] is: ham\n",
      "The best fit for: [ham\tSubject: recent publications...] is: ham\n",
      "The best fit for: [ham\tSubject: coling-acl ' 98 reg...] is: ham\n",
      "The best fit for: [ham\tSubject: nlp + ia 98 / tal +...] is: ham\n",
      "The best fit for: [ham\tSubject: tense mood selectio...] is: ham\n",
      "The best fit for: [ham\tSubject: language genderproj...] is: ham\n",
      "The best fit for: [ham\tSubject: amta workshop embed...] is: ham\n",
      "The best fit for: [ham\tSubject: semantics : il domi...] is: ham\n",
      "The best fit for: [ham\tSubject: books terminologyjo...] is: ham\n",
      "The best fit for: [ham\tSubject: books historical li...] is: ham\n",
      "The best fit for: [ham\tSubject: books written langu...] is: ham\n",
      "The best fit for: [ham\tSubject: books interpretingj...] is: ham\n",
      "The best fit for: [ham\tSubject: books latin linguis...] is: ham\n",
      "The best fit for: [ham\tSubject: books functional li...] is: ham\n",
      "The best fit for: [ham\tSubject: books history lingu...] is: ham\n",
      "The best fit for: [ham\tSubject: cssi conference spa...] is: ham\n",
      "The best fit for: [ham\tSubject: cilca viilong does ...] is: ham\n",
      "The best fit for: [ham\tSubject: transcription works...] is: ham\n",
      "The best fit for: [ham\tSubject: coling / acl worksh...] is: ham\n",
      "The best fit for: [ham\tSubject: thinking diagrams 1...] is: ham\n",
      "The best fit for: [ham\tSubject: avail review , phon...] is: ham\n",
      "The best fit for: [ham\tSubject: coling-acl 98 works...] is: ham\n",
      "The best fit for: [ham\tSubject: workshop sposs prel...] is: ham\n",
      "The best fit for: [ham\tSubject: brazilian internati...] is: ham\n",
      "The best fit for: [ham\tSubject: computationally - i...] is: ham\n",
      "The best fit for: [ham\tSubject: books : survey amer...] is: ham\n",
      "The best fit for: [ham\tSubject: wecol ' 98 - - west...] is: ham\n",
      "The best fit for: [ham\tSubject: euralex ' 98 - revi...] is: ham\n",
      "The best fit for: [spam\tSubject: secrets travel age...] is: spam\n",
      "The best fit for: [spam\tSubject: tami , was yu ?bob...] is: spam\n",
      "The best fit for: [spam\tSubject: internet pc user g...] is: ham\n",
      "The best fit for: [spam\tSubject: 95 . 8 capital fmi...] is: spam\n",
      "The best fit for: [spam\tSubject: business internet ...] is: spam\n",
      "The best fit for: [spam\tSubject: read ! !done dream...] is: spam\n",
      "The best fit for: [spam\tSubject: free gift catalogf...] is: spam\n",
      "The best fit for: [spam\tSubject: need photomask ? s...] is: spam\n",
      "The best fit for: [spam\tSubject: view hollander col...] is: ham\n",
      "The best fit for: [spam\tSubject: capitalfm . comis ...] is: spam\n",
      "The best fit for: [spam\tSubject: did information ye...] is: spam\n",
      "The best fit for: [spam\tSubject: strengthen marriag...] is: spam\n",
      "The best fit for: [spam\tSubject: bills under contro...] is: spam\n",
      "The best fit for: [spam\tSubject: win free trip anti...] is: spam\n",
      "The best fit for: [spam\tSubject: sunshine !vacation...] is: spam\n",
      "The best fit for: [spam\tSubject: capitalfm . comis ...] is: spam\n",
      "The best fit for: [spam\tSubject: search . . . credi...] is: spam\n",
      "The best fit for: [spam\tSubject: stocks move !pdc i...] is: spam\n",
      "The best fit for: [spam\tSubject: ez financenever se...] is: spam\n",
      "The best fit for: [spam\tSubject: * share ** share *...] is: spam\n",
      "The best fit for: [spam\tSubject: requestedinternati...] is: ham\n",
      "The best fit for: [spam\tSubject: offering closes ma...] is: spam\n",
      "The best fit for: [spam\tSubject: wow . . . is incre...] is: spam\n",
      "The best fit for: [spam\tSubject: http : / / capital...] is: spam\n",
      "The best fit for: [spam\tSubject: adv : \" free downl...] is: spam\n",
      "The best fit for: [spam\tSubject: free copy \" sellin...] is: spam\n",
      "The best fit for: [spam\tSubject: created !vacation ...] is: spam\n",
      "The best fit for: [spam\tSubject: financial freedom ...] is: spam\n",
      "The best fit for: [spam\tSubject: scitech internatio...] is: spam\n",
      "The best fit for: [spam\tSubject: adv : y2k . . . pr...] is: spam\n",
      "The best fit for: [spam\tSubject: inside scoop !is h...] is: spam\n",
      "The best fit for: [spam\tSubject: junk mail : books ...] is: ham\n",
      "The best fit for: [spam\tSubject: adv : paid surf ne...] is: spam\n",
      "The best fit for: [spam\tSubject: welcome jokes inte...] is: spam\n",
      "The best fit for: [spam\tSubject: april vip specials...] is: spam\n",
      "The best fit for: [spam\tSubject: been asked join ba...] is: ham\n",
      "The best fit for: [spam\tSubject: vacation !full det...] is: spam\n",
      "The best fit for: [spam\tSubject: capitalfm . comis ...] is: spam\n",
      "The best fit for: [spam\tSubject: re : major acquisi...] is: spam\n",
      "The best fit for: [spam\tSubject: webminingfree whit...] is: ham\n",
      "The best fit for: [spam\tSubject: angels - sent serv...] is: ham\n",
      "The best fit for: [spam\tSubject: lucky !congratulat...] is: spam\n",
      "The best fit for: [spam\tSubject: review book , pc m...] is: spam\n",
      "The best fit for: [spam\tSubject: stock market infor...] is: ham\n",
      "The best fit for: [spam\tSubject: lucky !congratulat...] is: spam\n",
      "The best fit for: [spam\tSubject: capitalfm . comis ...] is: spam\n",
      "The best fit for: [spam\tSubject: submit 600is spam ...] is: spam\n",
      "The best fit for: [spam\tSubject: submit 600is spam ...] is: spam\n",
      "The best fit for: [spam\tSubject: ' t stand ! ! ! ! ...] is: ham\n"
     ]
    }
   ],
   "source": [
    "// Test the model using the test data in testListArrayList\n",
    "\n",
    "try (InputStream dataInputStream = new FileInputStream(\"../data/spamtraining.train\")) {\n",
    "    // Create input stream for training data\n",
    "    InputStreamFactory isf = new InputStreamFactory() {\n",
    "    public InputStream createInputStream() throws IOException {\n",
    "            return dataInputStream;\n",
    "        }\n",
    "    };\n",
    "    \n",
    "    ObjectStream<String> objectStream = new PlainTextByLineStream(isf, StandardCharsets.UTF_8);\n",
    "    ObjectStream<DocumentSample> documentSampleStream = new DocumentSampleStream(objectStream);\n",
    "\n",
    "    DoccatModel documentCategorizationModel = DocumentCategorizerME.train(\"en\", documentSampleStream,\n",
    "                                                                         TrainingParameters.defaultParams(), new DoccatFactory());\n",
    "    DocumentCategorizerME documentCategorizer = new DocumentCategorizerME(documentCategorizationModel);\n",
    "    for (int i=0; i<testList.size(); i++) {\n",
    "        String testItem = testList.get(i);\n",
    "        String[] testWords = testItem.replaceAll(\"[^A-Za-z]\", \" \").split(\" \");\n",
    "        double[] probabilities = documentCategorizer.categorize(testWords);\n",
    "        String bestCategory = documentCategorizer.getBestCategory(probabilities);\n",
    "        System.out.println(\"The best fit for: [\" + testItem.subSequence(0, 32) + \"...] is: \" + bestCategory);\n",
    "    }\n",
    "    \n",
    "} catch (FileNotFoundException ex) {\n",
    "    // Handle exceptions\n",
    "    System.out.println(\"Cant find files\");\n",
    "} catch (IOException ex) {\n",
    "    // Handle exceptions\n",
    "    System.err.print(\"ERROR: File containing _______ information not found:\\n\");\n",
    "    ex.printStackTrace();\n",
    "    //System.exit(1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard-coding Regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.BufferedReader;\n",
    "import java.io.File;\n",
    "import java.io.FileNotFoundException;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.util.regex.Matcher;\n",
    "import java.util.regex.Pattern;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "public void isSpam(String text) {\n",
    "    try (BufferedReader br = new BufferedReader(new FileReader(new File(\"../data/spam-examples.txt\")))) {\n",
    "        String line = null;\n",
    "        while ((line = br.readLine()) != null) {\n",
    "            Pattern pattern = Pattern.compile(line);\n",
    "            Matcher matcher = pattern.matcher(text);\n",
    "            if (matcher.find() == true) {\n",
    "                System.out.println(\"Spam detected\");\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "    } catch (FileNotFoundException e) {\n",
    "        // Handle exceptions\n",
    "        System.out.println(\"spam-examples.txt not found\");\n",
    "    } catch (IOException e) {\n",
    "        // Handle exceptions\n",
    "        System.err.print(\"ERROR: File containing _______ information not found:\\n\");\n",
    "        e.printStackTrace();\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam detected\n"
     ]
    }
   ],
   "source": [
    "// test String\n",
    "String testString = \"Congratualtions! You have won! Click here...\";\n",
    "isSpam(testString);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "14.0.1+7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
