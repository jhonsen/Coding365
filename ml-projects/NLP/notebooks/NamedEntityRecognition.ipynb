{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "- Using regular expressions to find entities\n",
    "- Using chunks with regular exp to identify entities\n",
    "- Using OpenNLP to find entities in text\n",
    "- Isolating multiple entities types\n",
    "- Using a CRF model to find entities in a document\n",
    "- Using a chunker to find entities\n",
    "- Training a specialized NER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp@nlpworks.com [29:45]\n",
      "mrnlp@nlpworks.org [74:92]\n"
     ]
    }
   ],
   "source": [
    "import java.util.regex.Matcher;\n",
    "import java.util.regex.Pattern;\n",
    "\n",
    "String sampleText = \"I can normally be reached at nlp@nlpworks.com. \" + \"If not you can email me at mrnlp@nlpworks.org\";\n",
    "String emailRegularExpression = \"[a-zA-Z0-9'._%+-]+@\" + \"(?:[a-zA-Z0-9-]+\\\\.)\" + \"+[a-zA-Z]{2,4}\";\n",
    "Pattern pattern = Pattern.compile(emailRegularExpression);\n",
    "Matcher matcher = pattern.matcher(sampleText);\n",
    "\n",
    "while (matcher.find()) {\n",
    "    System.out.println(matcher.group() + \" [\" + matcher.start() + \":\" + \n",
    "        matcher.end() + \"]\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888-555-1111 [20:32]\n",
      "55555-4444 [66:76]\n"
     ]
    }
   ],
   "source": [
    "String phoneNumberRegularExpression = \"\\\\d{3}-\\\\d{3}-\\\\d{4}\";\n",
    "String zipCodeRegularExpression = \"[0-9]{5}(\\\\-?[0-9]{4})?\";\n",
    "pattern = Pattern.compile(phoneNumberRegularExpression + \"|\" + \n",
    " zipCodeRegularExpression + \"|\" + emailRegularExpression);\n",
    " sampleText = \"Her phone number is 888-555-1111. You may also need her ZIP code: 55555-4444\";\n",
    "\n",
    "matcher = pattern.matcher(sampleText);\n",
    "while (matcher.find()) {\n",
    "    System.out.println(matcher.group() + \" [\" + matcher.start() + \":\" + \n",
    "        matcher.end() + \"]\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LINGPipe's Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>de.julielab</groupId>\n",
    "    <artifactId>aliasi-lingpipe</artifactId>\n",
    "    <version>4.1.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: hisemail@somecompany.com\tType: EMAIL\n"
     ]
    }
   ],
   "source": [
    "import java.util.Set;\n",
    "import com.aliasi.chunk.Chunk;\n",
    "import com.aliasi.chunk.Chunker;\n",
    "import com.aliasi.chunk.Chunking;\n",
    "import com.aliasi.chunk.RegExChunker;\n",
    "\n",
    "String sampleText = \"His email address is hisemail@somecompany.com.\";\n",
    "String emailRegularExpression = \"[A-Za-z0-9](([_\\\\.\\\\-]?[a-zA-Z0-9]+)*)@(\" + \n",
    "    \"[A-Za-z0-9]+)(([\\\\.\\\\-]?[a-zA-Z0-9]+)*)\\\\.([A-Za-z]{2,})\";\n",
    "\n",
    "Chunker chunker = new RegExChunker(emailRegularExpression,\"EMAIL\",1.0);\n",
    "Chunking chunking = chunker.chunk(sampleText);\n",
    "Set<Chunk> chunkSet = chunking.chunkSet();\n",
    "\n",
    "for (Chunk chunk : chunkSet) {\n",
    "    System.out.println(\"Entity: \" + \n",
    "        sampleText.substring(chunk.start(), chunk.end()) + \n",
    "        \"\\tType: \" + chunk.type());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenNLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>org.apache.opennlp</groupId>\n",
    "    <artifactId>opennlp-tools</artifactId>\n",
    "    <version>1.9.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.InputStream;\n",
    "import opennlp.tools.namefind.NameFinderME;\n",
    "import opennlp.tools.namefind.TokenNameFinderModel;\n",
    "import opennlp.tools.tokenize.Tokenizer;\n",
    "import opennlp.tools.tokenize.TokenizerME;\n",
    "import opennlp.tools.tokenize.TokenizerModel;\n",
    "import opennlp.tools.util.Span;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: [1850s] was a date entity found starting at 6 and ending at 7\n",
      "Date: 1850s  Probability: 0.878211895731101\n",
      "Entity: [March] was a date entity found starting at 13 and ending at 15\n",
      "Date: March 3  Probability: 0.9937399307548391\n"
     ]
    }
   ],
   "source": [
    "try (InputStream tokenStream = new FileInputStream(new File(\"../models/en-token.bin\"));\n",
    "        InputStream entityModelInputStream = new FileInputStream(new File(\"../models/en-ner-date.bin\"));) {\n",
    "    TokenizerModel tokenizerModel = new TokenizerModel(tokenStream);\n",
    "    Tokenizer tokenizer = new TokenizerME(tokenizerModel);\n",
    "    TokenNameFinderModel tokenNameFinderModel = new TokenNameFinderModel(entityModelInputStream);\n",
    "    // set class instance\n",
    "    NameFinderME nameFinderME = new NameFinderME(tokenNameFinderModel);\n",
    "\n",
    "    String text = \"The city was founded in the 1850s and its first mayor was born March 3, 1832.\";\n",
    "    String tokens[] = tokenizer.tokenize(text);\n",
    "    Span dateSpans[] = nameFinderME.find(tokens);\n",
    "\n",
    "    for (int i = 0; i < dateSpans.length; i++) {\n",
    "        System.out.print(\"Entity: [\" + tokens[dateSpans[i].getStart()]);\n",
    "        System.out.print(\"] was a \" + dateSpans[i].getType() + \" entity found starting at \" + dateSpans[i].getStart());\n",
    "        System.out.println(\" and ending at \" + dateSpans[i].getEnd());\n",
    "        \n",
    "        // to get actual spans\n",
    "        String date = \"\";\n",
    "        for(int j=dateSpans[i].getStart(); j< dateSpans[i].getEnd(); j++) {\n",
    "            date += tokens[j] + \" \"; \n",
    "        }\n",
    "        // To get probabilities\n",
    "        double[] spanProbs = nameFinderME.probs(dateSpans);\n",
    "        System.out.println(\"Date: \" + date + \" Probability: \" + spanProbs[i]);\n",
    "    }\n",
    "    \n",
    "} catch (Exception ex) {\n",
    " // Handle exception\n",
    "    System.out.println(\"Could not find model files\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying multiple entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.InputStream;\n",
    "import java.util.ArrayList;\n",
    "import opennlp.tools.namefind.NameFinderME;\n",
    "import opennlp.tools.namefind.TokenNameFinderModel;\n",
    "import opennlp.tools.tokenize.Tokenizer;\n",
    "import opennlp.tools.tokenize.TokenizerME;\n",
    "import opennlp.tools.tokenize.TokenizerModel;\n",
    "import opennlp.tools.util.Span;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "String sentences[] = { \n",
    "    \"Sam and Mary left on Friday, November 12. \",\n",
    "    \"They stopped in Boston at an ATM to get $300 for expenses. \",\n",
    "    \"While they were there Sam bumped into an old friend who was on his way to work at ATT. \",\n",
    "    \"They decided to leave together and departed for Maine\" };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "\tEntity: Sam - Entity Type: person\n",
      "\tEntity: Mary - Entity Type: person\n",
      "Sentence 2\n",
      "\tEntity: Boston - Entity Type: location\n",
      "\tEntity: $300 - Entity Type: money\n",
      "Sentence 3\n",
      "Sentence 4\n",
      "\tEntity: Maine - Entity Type: location\n"
     ]
    }
   ],
   "source": [
    "try (InputStream tokenStream = new FileInputStream(new File(\"../models/en-token.bin\"))) {\n",
    "    TokenizerModel tokenModel = new TokenizerModel(tokenStream);\n",
    "    \n",
    "    Tokenizer tokenizer = new TokenizerME(tokenModel);\n",
    "    String modelNames[] = { \n",
    "        \"../models/en-ner-person.bin\", \"../models/en-ner-location.bin\", \n",
    "        \"../models/en-ner-organization.bin\", \"../models/en-ner-money.bin\", \n",
    "        \"../models/en-ner-time.bin\" \n",
    "    };\n",
    "    for (int i = 0; i < sentences.length; i++) {\n",
    "        System.out.println(\"Sentence \" + (i + 1));\n",
    "        for (String name : modelNames) {\n",
    "            TokenNameFinderModel entityModel = new TokenNameFinderModel(new FileInputStream(new File(name)));\n",
    "            NameFinderME nameFinderME = new NameFinderME(entityModel);\n",
    "            \n",
    "            // process sentence\n",
    "            String tokens[] = tokenizer.tokenize(sentences[i]);\n",
    "            Span spans[] = nameFinderME.find(tokens);\n",
    "            \n",
    "            // find location of entities\n",
    "            for (Span span : spans) {\n",
    "                System.out.print(\"\\tEntity: \");\n",
    "                for (int j = span.getStart(); j < span.getEnd(); j++) {\n",
    "                    System.out.print(tokens[j]);\n",
    "                }\n",
    "                System.out.println(\" - Entity Type: \" + span.getType());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "} catch (Exception ex) {\n",
    "// Handle exceptions\n",
    "    System.out.println(\"Cant find model files\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "14.0.1+7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
