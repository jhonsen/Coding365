{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Natural Language Processing with Java Cookbook [Packt](https://www.packtpub.com/product/natural-language-processing-with-java-cookbook/9781789801156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing with OpenNLP Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load POM dependencies from [OpenNLP](https://opennlp.apache.org/maven-dependency.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<repositories>\n",
    "  <repository>\n",
    "    <id>apache opennlp snapshot</id>\n",
    "    <url>https://repository.apache.org/content/repositories/snapshots/</url>\n",
    "  </repository>\n",
    "</repositories>\n",
    "\n",
    "<dependency>\n",
    "    <groupId>org.apache.opennlp</groupId>\n",
    "    <artifactId>opennlp-tools</artifactId>\n",
    "    <version>1.9.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **SimpleTokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "the\n",
      "best\n",
      "day\n",
      "of\n",
      "my\n",
      "life\n",
      ",\n",
      "as\n",
      "some\n",
      "would\n",
      "say\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import opennlp.tools.tokenize.SimpleTokenizer;\n",
    "\n",
    "public void tokenizeSentence(String sentence) {\n",
    "    SimpleTokenizer simpletkn = SimpleTokenizer.INSTANCE;\n",
    "    String tokenList[] = simpletkn.tokenize(sentence);\n",
    "    for (String token: tokenList) {\n",
    "        System.out.println(token);\n",
    "    }\n",
    "}\n",
    "\n",
    "String phrase = \"This is the best day of my life, as some would say.\";\n",
    "tokenizeSentence(phrase);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing with OpenNLP's Maximum Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.FileNotFoundException;\n",
    "import java.io.IOException;\n",
    "import java.io.File;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.InputStream;\n",
    "import opennlp.tools.tokenize.Tokenizer;\n",
    "import opennlp.tools.tokenize.TokenizerME;\n",
    "import opennlp.tools.tokenize.TokenizerModel;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "the\n",
      "best\n",
      "day\n",
      "indeed\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "public void tokenizeMaxEntropy(String phrase){\n",
    "    try (InputStream modelInputStream = new FileInputStream(new File(\"../models/\", \"en-token.bin\"))) {\n",
    "        TokenizerModel tknModel = new TokenizerModel(modelInputStream);\n",
    "        Tokenizer tokenizer = new TokenizerME(tknModel);\n",
    "        \n",
    "        String tokenList[] = tokenizer.tokenize(phrase);\n",
    "        for (String token: tokenList) { System.out.println(token);}\n",
    "    } catch (FileNotFoundException e) {\n",
    "        System.out.println(\"File is not found\");\n",
    "    } catch (IOException e) {\n",
    "        // Handle\n",
    "    }\n",
    "}\n",
    "\n",
    "String sampleText = \"This is the best day indeed!\";\n",
    "tokenizeMaxEntropy(sampleText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing manually with Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "the\n",
      "best\n",
      "day\n",
      "of\n",
      "my\n",
      "life,\n",
      "as\n",
      "some\n",
      "would\n",
      "say.\n"
     ]
    }
   ],
   "source": [
    "import java.util.ArrayList;\n",
    "import java.util.Scanner;\n",
    "\n",
    "public void tokenizeManually(String phrase){\n",
    "    Scanner scanner = new Scanner(phrase);\n",
    "    ArrayList<String> list = new ArrayList<>();\n",
    "    while (scanner.hasNext()) {\n",
    "        String token = scanner.next();\n",
    "        list.add(token);\n",
    "    }\n",
    "    \n",
    "    for (String token : list) { System.out.println(token); }\n",
    "}\n",
    "\n",
    "String phrase = \"This is the best day of my life, as some would say.\";\n",
    "tokenizeManually(phrase);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "14.0.1+7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
