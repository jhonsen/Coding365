{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Sentences from a text (Sentence Boundary Decision `SBD`) \n",
    "- Finding sentences using the Java core API\n",
    "- Performing SBD using the BreakIterator class\n",
    "- Using OpenNLP to perform SBD\n",
    "- Using the Stanford NLP API to perform SBD\n",
    "- Using the LingPipe and chunking to perform SBD\n",
    "- Performing SBD on specialized text\n",
    "- Training a neural network to perform SBD with specialized text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Core Java Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.regex.Matcher;\n",
    "import java.util.regex.Pattern;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "String text = \"We will start with a simple sentence. However, is it \"\n",
    "    + \"possible for a sentence to end with a question \"\n",
    "    + \"mark? Obviously that is possible! Another \"\n",
    "    + \"complication is the use of a number such as 56.32 \"\n",
    "    + \"or ellipses such as ... Ellipses may be found ... \"\n",
    "    + \"with a sentence! Of course, we may also find the \"\n",
    "    + \"use of abbreviations such as Mr. Smith or \"\n",
    "    + \"Dr. Jones.\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will start with a simple sentence\n",
      " However, is it possible for a sentence to end with a question mark\n",
      " Obviously that is possible\n",
      " Another complication is the use of a number such as 56\n",
      "32 or ellipses such as \n",
      "\n",
      "\n",
      " Ellipses may be found \n",
      "\n",
      "\n",
      " with a sentence\n",
      " Of course, we may also find the use of abbreviations such as Mr\n",
      " Smith or Dr\n",
      " Jones\n"
     ]
    }
   ],
   "source": [
    "String sentenceDelimiters = \"[.?!]\";\n",
    "String[] sentences = (text.split(sentenceDelimiters));\n",
    "for (String sentence : sentences) {\n",
    "    System.out.println(sentence);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will start with a simple sentence.\n",
      " However, is it possible for a sentence to end with a question mark?\n",
      " Obviously that is possible!\n",
      " Another complication is the use of a number such as 56.\n",
      " or ellipses such as .\n",
      " Ellipses may be found .\n",
      " with a sentence!\n",
      " Of course, we may also find the use of abbreviations such as Mr.\n",
      " Smith or Dr.\n",
      " Jones.\n"
     ]
    }
   ],
   "source": [
    "Pattern sentencePattern = Pattern.compile(\"\\\\s+[^.!?]*[.!?]\");\n",
    "Matcher matcher = sentencePattern.matcher(text);\n",
    "while (matcher.find()) {\n",
    "    System.out.println(matcher.group());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `BreakIterator` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.text.BreakIterator;\n",
    "\n",
    "private static String text =     \"We will start with a simple sentence. However, is it \"\n",
    "    + \"possible for a sentence to end with a question \"\n",
    "    + \"mark? Obviously that is possible! Another \"\n",
    "    + \"complication is the use of a number such as 56.32 \"\n",
    "    + \"or ellipses such as ... Ellipses may be found ... \"\n",
    "    + \"with a sentence! Of course, we may also find the \"\n",
    "    + \"use of abbreviations such as Mr. Smith or \"\n",
    "    + \"Dr. Jones.\";\n",
    "\n",
    "BreakIterator breakIterator = BreakIterator.getSentenceInstance();\n",
    "breakIterator.setText(text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-38 [We will start with a simple sentence. ]\n",
      "38-106 [However, is it possible for a sentence to end with a question mark? ]\n",
      "106-134 [Obviously that is possible! ]\n",
      "134-216 [Another complication is the use of a number such as 56.32 or ellipses such as ... ]\n",
      "216-259 [Ellipses may be found ... with a sentence! ]\n",
      "259-324 [Of course, we may also find the use of abbreviations such as Mr. ]\n",
      "324-337 [Smith or Dr. ]\n",
      "337-343 [Jones.]\n"
     ]
    }
   ],
   "source": [
    "int startPosition = breakIterator.first();\n",
    "int endingPosition = breakIterator.first();\n",
    "\n",
    "while (true) {\n",
    "    endingPosition = breakIterator.next();\n",
    "    if (endingPosition == BreakIterator.DONE) {\n",
    "        break;\n",
    "    } else {\n",
    "        System.out.println(startPosition + \"-\" + endingPosition + \" [\" + text.substring(startPosition, endingPosition) + \"]\");\n",
    "        startPosition = endingPosition;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343-343 [Jones.] \n"
     ]
    }
   ],
   "source": [
    "// to get the last sentence\n",
    "breakIterator.setText(text);\n",
    "\n",
    "int endingPosition = breakIterator.last();\n",
    "int startingPosition = breakIterator.previous();\n",
    "System.out.println(startPosition + \"-\" + endingPosition + \" [\" + text.substring(startingPosition, endingPosition) + \"] \");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenNLP's `SentenceDetectorME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>org.apache.opennlp</groupId>\n",
    "    <artifactId>opennlp-tools</artifactId>\n",
    "    <version>1.9.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.FileNotFoundException;\n",
    "import java.io.IOException;\n",
    "import java.io.InputStream;\n",
    "import opennlp.tools.sentdetect.SentenceDetectorME;\n",
    "import opennlp.tools.sentdetect.SentenceModel;\n",
    "import opennlp.tools.util.Span;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "private static String text = \n",
    "    \"We will start with a simple sentence. However, is it \"\n",
    "    + \"possible for a sentence to end with a question \"\n",
    "    + \"mark? Obviously that is possible! Another \"\n",
    "    + \"complication is the use of a number such as 56.32 \"\n",
    "    + \"or ellipses such as ... Ellipses may be found ... \"\n",
    "    + \"with a sentence! Of course, we may also find the \"\n",
    "    + \"use of abbreviations such as Mr. Smith or \"\n",
    "    + \"Dr. Jones.\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[We will start with a simple sentence.]\n",
      "[However, is it possible for a sentence to end with a question mark?]\n",
      "[Obviously that is possible!]\n",
      "[Another complication is the use of a number such as 56.32 or ellipses such as ... Ellipses may be found ... with a sentence!]\n",
      "[Of course, we may also find the use of abbreviations such as Mr. Smith or Dr. Jones.]\n",
      "[0..37)\n",
      "[38..105)\n",
      "[106..133)\n",
      "[134..258)\n",
      "[259..343)\n",
      "Sentence 0: 0.9999\n",
      "Sentence 1: 0.8117\n",
      "Sentence 2: 0.9898\n",
      "Sentence 3: 0.9953\n",
      "Sentence 4: 0.9706\n"
     ]
    }
   ],
   "source": [
    "try (InputStream inputStream = new FileInputStream(new File(\"../models/en-sent.bin\"))) {\n",
    "    // Prints      \n",
    "    SentenceModel sentenceModel = new SentenceModel(inputStream);\n",
    "    SentenceDetectorME sentenceDetector = new SentenceDetectorME(sentenceModel);\n",
    "    String sentences[] = sentenceDetector.sentDetect(text);\n",
    "    for (String sentence : sentences) {\n",
    "        System.out.println(\"[\" + sentence + \"]\");\n",
    "    }\n",
    "    \n",
    "    // Span objects hold the starting and ending position\n",
    "    Span spans[] = sentenceDetector.sentPosDetect(text);\n",
    "    for (Span span : spans) {\n",
    "        System.out.println(span);\n",
    "    }\n",
    "    \n",
    "    double probablities[] = sentenceDetector.getSentenceProbabilities();\n",
    "    for(int i=0; i<sentences.length; i++) {\n",
    "        System.out.printf(\"Sentence %d: %6.4f\\n\",i, probablities[i]);\n",
    "    }\n",
    "    \n",
    "} catch (FileNotFoundException ex) {\n",
    "    // Handle exceptions\n",
    "    System.out.println(\"System file not found\");\n",
    "} catch (IOException ex) {\n",
    "    // Handle exceptions\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using StanfordNLP's `WordToSentenceProcessor` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: problems summary ::\n",
      ":::: ERRORS\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%loadFromPOM\n",
    "<!-- https://mvnrepository.com/artifact/edu.stanford.nlp/stanford-corenlp -->\n",
    "<dependency>\n",
    "    <groupId>edu.stanford.nlp</groupId>\n",
    "    <artifactId>stanford-corenlp</artifactId>\n",
    "    <version>4.2.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.StringReader;\n",
    "import java.util.List;\n",
    "import edu.stanford.nlp.ling.CoreLabel;\n",
    "import edu.stanford.nlp.process.CoreLabelTokenFactory;\n",
    "import edu.stanford.nlp.process.PTBTokenizer;\n",
    "import edu.stanford.nlp.process.WordToSentenceProcessor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[We, will, start, with, a, simple, sentence, .]\n",
      "[However, ,, is, it, possible, for, a, sentence, to, end, with, a, question, mark, ?]\n",
      "[Obviously, that, is, possible, !]\n",
      "[Another, complication, is, the, use, of, a, number, such, as, 56.32, or, ellipses, such, as, ..., Ellipses, may, be, found, ..., with, a, sentence, !]\n",
      "[Of, course, ,, we, may, also, find, the, use, of, abbreviations, such, as, Mr., Smith, or, Dr., Jones, .]\n"
     ]
    }
   ],
   "source": [
    "private static String text =  \"We will start with a simple sentence. However, is it \"\n",
    "    + \"possible for a sentence to end with a question \"\n",
    "    + \"mark? Obviously that is possible! Another \"\n",
    "    + \"complication is the use of a number such as 56.32 \"\n",
    "    + \"or ellipses such as ... Ellipses may be found ... \"\n",
    "    + \"with a sentence! Of course, we may also find the \"\n",
    "    + \"use of abbreviations such as Mr. Smith or \"\n",
    "    + \"Dr. Jones.\";\n",
    "\n",
    "PTBTokenizer<CoreLabel> ptbTokenizer = new PTBTokenizer<CoreLabel>(new StringReader(text),new CoreLabelTokenFactory(), null);\n",
    "WordToSentenceProcessor<CoreLabel> wordToSentenceProcessor = new WordToSentenceProcessor<CoreLabel>();\n",
    "List<List<CoreLabel>> sentenceList = wordToSentenceProcessor.process(ptbTokenizer.tokenize());\n",
    "\n",
    "for (List<CoreLabel> sentence : sentenceList) {\n",
    "    System.out.println(sentence);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will start with a simple sentence . \n",
      "However , is it possible for a sentence to end with a question mark ? \n",
      "Obviously that is possible ! \n",
      "Another complication is the use of a number such as 56.32 or ellipses such as ... Ellipses may be found ... with a sentence ! \n",
      "Of course , we may also find the use of abbreviations such as Mr. Smith or Dr. Jones . \n"
     ]
    }
   ],
   "source": [
    "for (List<CoreLabel> sentence : sentenceList) {\n",
    "    for (CoreLabel coreLabel : sentence) {\n",
    "        System.out.print(coreLabel + \" \");\n",
    "    }\n",
    "    System.out.println();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We - 0:2 will - 3:7 start - 8:13 with - 14:18 a - 19:20 simple - 21:27 sentence - 28:36 . - 36:37 However - 38:45 , - 45:46 is - 47:49 it - 50:52 possible - 53:61 for - 62:65 a - 66:67 sentence - 68:76 to - 77:79 end - 80:83 with - 84:88 a - 89:90 question - 91:99 mark - 100:104 ? - 104:105 Obviously - 106:115 that - 116:120 is - 121:123 possible - 124:132 ! - 132:133 Another - 134:141 complication - 142:154 is - 155:157 the - 158:161 use - 162:165 of - 166:168 a - 169:170 number - 171:177 such - 178:182 as - 183:185 56.32 - 186:191 or - 192:194 ellipses - 195:203 such - 204:208 as - 209:211 ... - 212:215 Ellipses - 216:224 may - 225:228 be - 229:231 found - 232:237 ... - 238:241 with - 242:246 a - 247:248 sentence - 249:257 ! - 257:258 Of - 259:261 course - 262:268 , - 268:269 we - 270:272 may - 273:276 also - 277:281 find - 282:286 the - 287:290 use - 291:294 of - 295:297 abbreviations - 298:311 such - 312:316 as - 317:319 Mr. - 320:323 Smith - 324:329 or - 330:332 Dr. - 333:336 Jones - 337:342 . - 342:343 \n"
     ]
    }
   ],
   "source": [
    "//  To get position of each word\n",
    "for (List<CoreLabel> sentence : sentenceList) {\n",
    "    for (CoreLabel coreLabel : sentence) {\n",
    "        System.out.print(coreLabel.word() + \" - \" +  \n",
    "            coreLabel.beginPosition() + \":\" +\n",
    "            coreLabel.endPosition() + \" \");\n",
    "    }\n",
    "}\n",
    "System.out.println();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LINGPipe & Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>de.julielab</groupId>\n",
    "    <artifactId>aliasi-lingpipe</artifactId>\n",
    "    <version>4.1.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "import com.aliasi.sentences.IndoEuropeanSentenceModel;\n",
    "import com.aliasi.sentences.SentenceModel;\n",
    "import com.aliasi.tokenizer.IndoEuropeanTokenizerFactory;\n",
    "import com.aliasi.tokenizer.Tokenizer;\n",
    "import com.aliasi.tokenizer.TokenizerFactory;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "String text = \n",
    "    \"We will start with a simple sentence. However, is it \"\n",
    "    + \"possible for a sentence to end with a question \"\n",
    "    + \"mark? Obviously that is possible! Another \"\n",
    "    + \"complication is the use of a number such as 56.32 \"\n",
    "    + \"or ellipses such as ... Ellipses may be found ... \"\n",
    "    + \"with a sentence! Of course, we may also find the \"\n",
    "    + \"use of abbreviations such as Mr. Smith or \"\n",
    "    + \"Dr. Jones.\";\n",
    "TokenizerFactory tokenizerFactory = IndoEuropeanTokenizerFactory.INSTANCE;\n",
    "SentenceModel sentenceModel = new IndoEuropeanSentenceModel();\n",
    "\n",
    "List<String> tokenList = new ArrayList<>();\n",
    "List<String> whiteList = new ArrayList<>();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer tokenizer = tokenizerFactory.tokenizer(text.toCharArray(), 0, text.length());\n",
    "tokenizer.tokenize(tokenList, whiteList);\n",
    "\n",
    "int[] sentenceBoundaries = sentenceModel.boundaryIndices(\n",
    "    tokenList.toArray(new String[tokenList.size()]),\n",
    "    whiteList.toArray(new String[whiteList.size()]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[We will start with a simple sentence. ]\n",
      "[However, is it possible for a sentence to end with a question mark? ]\n",
      "[Obviously that is possible! ]\n",
      "[Another complication is the use of a number such as 56.32 or ellipses such as ... Ellipses may be found ... with a sentence! ]\n",
      "[Of course, we may also find the use of abbreviations such as Mr. Smith or Dr. Jones.]\n"
     ]
    }
   ],
   "source": [
    "// display sentences\n",
    "int start = 0;\n",
    "for (int boundary : sentenceBoundaries) {\n",
    "    System.out.print(\"[\");\n",
    "    while (start <= boundary) {\n",
    "        System.out.print(tokenList.get(start) + \n",
    "            whiteList.get(start + 1));\n",
    "        start++;\n",
    "    }\n",
    "    System.out.println(\"]\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:7\n",
      "7:22\n",
      "22:27\n",
      "27:52\n",
      "52:73\n"
     ]
    }
   ],
   "source": [
    "// Print sentence boundaries\n",
    "int begin = 0;\n",
    "for (int boundary : sentenceBoundaries) {\n",
    "    System.out.println(begin + \":\" + boundary);\n",
    "    begin = boundary;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LINGPipe for specialized text\n",
    "e.g., medical literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "     <groupId>de.julielab</groupId>\n",
    "     <artifactId>aliasi-lingpipe</artifactId>\n",
    "     <version>4.1.0</version>\n",
    " </dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.aliasi.chunk.Chunk;\n",
    "import com.aliasi.chunk.Chunking;\n",
    "import com.aliasi.sentences.MedlineSentenceModel;\n",
    "import com.aliasi.sentences.SentenceChunker;\n",
    "import com.aliasi.tokenizer.IndoEuropeanTokenizerFactory;\n",
    "import com.aliasi.tokenizer.TokenizerFactory;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "String text = \"In total, 33 patients with AIS and 39 healthy \"\n",
    "    + \"controls were enrolled in this study. The major \"\n",
    "    + \"findings were as follows: (1) The stroke group had \"\n",
    "    + \"a significantly lower level of serum Hg (6.4?±?4.3 \"\n",
    "    + \"µg/L vs. 9.8?±?7.0 µg/L, P =?0.032, OR?=?0.90, 95% \"\n",
    "    + \"CI?=?0.81–0.99) and a lower level of urine Hg \"\n",
    "    + \"(0.7?±?0.7 µg/L vs. 1.2?±?0.6 µg/L, P =?0.006, \"\n",
    "    + \"OR?=?0.27, 95% CI?=?0.11–0.68) than the control \"\n",
    "    + \"group. (2) No significant difference in serum \"\n",
    "    + \"Pb (S-Pb), As (S-As), and Cd (S-Cd) levels and \"\n",
    "    + \"urine Pb (U-Pb), As (U-As) and Cd (U-Cd) levels \"\n",
    "    + \"was observed in either group.\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenizerFactory tokenizerfactory = IndoEuropeanTokenizerFactory.INSTANCE;\n",
    "MedlineSentenceModel medlineSentenceModel = new MedlineSentenceModel();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In total, 33 patients with AIS and 39 healthy controls were enrolled in this study.]\n",
      "[The major findings were as follows: (1) The stroke group had a significantly lower level of serum Hg (6.4?±?4.3 µg/L vs. 9.8?±?7.0 µg/L, P =?0.032, OR?=?0.90, 95% CI?=?0.81–0.99) and a lower level of urine Hg (0.7?±?0.7 µg/L vs. 1.2?±?0.6 µg/L, P =?0.006, OR?=?0.27, 95% CI?=?0.11–0.68) than the control group.]\n",
      "[(2) No significant difference in serum Pb (S-Pb), As (S-As), and Cd (S-Cd) levels and urine Pb (U-Pb), As (U-As) and Cd (U-Cd) levels was observed in either group.]\n"
     ]
    }
   ],
   "source": [
    "SentenceChunker sentenceChunker = new SentenceChunker(tokenizerfactory,  medlineSentenceModel);\n",
    "Chunking chunking = sentenceChunker.chunk(text.toCharArray(),0, text.length());\n",
    "String slice = chunking.charSequence().toString();\n",
    "\n",
    "for (Chunk chunk : chunking.chunkSet()) {\n",
    "    System.out.println(\"[\" +  slice.substring(chunk.start(), chunk.end()) + \"]\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an NN for specialized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>org.apache.opennlp</groupId>\n",
    "    <artifactId>opennlp-tools</artifactId>\n",
    "    <version>1.9.0</version>\n",
    "</dependency>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.BufferedOutputStream;\n",
    "import java.io.ByteArrayInputStream;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.FileNotFoundException;\n",
    "import java.io.FileOutputStream;\n",
    "import java.io.IOException;\n",
    "import java.io.InputStream;\n",
    "import java.io.OutputStream;\n",
    "import java.nio.charset.Charset;\n",
    "import opennlp.tools.sentdetect.SentenceDetectorFactory;\n",
    "import opennlp.tools.sentdetect.SentenceDetectorME;\n",
    "import opennlp.tools.sentdetect.SentenceModel;\n",
    "import opennlp.tools.sentdetect.SentenceSample;\n",
    "import opennlp.tools.sentdetect.SentenceSampleStream;\n",
    "import opennlp.tools.util.ObjectStream;\n",
    "import opennlp.tools.util.PlainTextByLineStream;\n",
    "import opennlp.tools.util.TrainingParameters;\n",
    "\n",
    "String terminators[] = { \".\", \"!\", \"?\", \"...\" };\n",
    "String sampleSentences[] = {\"A simple sentence\", \"Another sentence a bit longer\", \"Last sentence\"};\n",
    "\n",
    "StringBuilder stringBuilder = new StringBuilder();\n",
    "for (String sentenceTerminator : terminators) {\n",
    "    for (String sentence : sampleSentences) {\n",
    "        stringBuilder.append(sentence).append(sentenceTerminator);\n",
    "        stringBuilder.append(System.lineSeparator());\n",
    "    }\n",
    "}\n",
    "\n",
    "String trainingSentences = stringBuilder.toString();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing events with TwoPass using cutoff of 5\n",
      "\n",
      "\tComputing event counts...  done. 18 events\n",
      "\tIndexing...  done.\n",
      "Sorting and merging events... done. Reduced 18 events to 14.\n",
      "Done indexing in 0.01 s.\n",
      "Incorporating indexed data for training...  \n",
      "done.\n",
      "\tNumber of Event Tokens: 14\n",
      "\t    Number of Outcomes: 2\n",
      "\t  Number of Predicates: 10\n",
      "...done.\n",
      "Computing model parameters ...\n",
      "Performing 100 iterations.\n",
      "  1:  ... loglikelihood=-12.476649250079015\t0.6666666666666666\n",
      "  2:  ... loglikelihood=-10.1788351655278\t0.6666666666666666\n",
      "  3:  ... loglikelihood=-9.365516819465263\t0.7222222222222222\n",
      "  4:  ... loglikelihood=-8.806470120346262\t0.7222222222222222\n",
      "  5:  ... loglikelihood=-8.370920558495053\t0.7222222222222222\n",
      "  6:  ... loglikelihood=-8.016876393960429\t0.7222222222222222\n",
      "  7:  ... loglikelihood=-7.721000129401042\t0.7222222222222222\n",
      "  8:  ... loglikelihood=-7.468442127395042\t0.7222222222222222\n",
      "  9:  ... loglikelihood=-7.249170139289655\t0.8333333333333334\n",
      " 10:  ... loglikelihood=-7.05609282775734\t0.8333333333333334\n",
      " 11:  ... loglikelihood=-6.884014635929351\t0.8333333333333334\n",
      " 12:  ... loglikelihood=-6.7290222599565155\t0.8333333333333334\n",
      " 13:  ... loglikelihood=-6.588105145250323\t0.8333333333333334\n",
      " 14:  ... loglikelihood=-6.458908786345309\t0.8333333333333334\n",
      " 15:  ... loglikelihood=-6.3395672965158365\t0.8333333333333334\n",
      " 16:  ... loglikelihood=-6.228585715911661\t0.8333333333333334\n",
      " 17:  ... loglikelihood=-6.124754959749414\t0.8333333333333334\n",
      " 18:  ... loglikelihood=-6.027089007741018\t0.8333333333333334\n",
      " 19:  ... loglikelihood=-5.934777715854163\t0.8333333333333334\n",
      " 20:  ... loglikelihood=-5.847150868210804\t0.8333333333333334\n",
      " 21:  ... loglikelihood=-5.76365047193284\t0.8333333333333334\n",
      " 22:  ... loglikelihood=-5.683809190710271\t0.8333333333333334\n",
      " 23:  ... loglikelihood=-5.607233408613957\t0.8333333333333334\n",
      " 24:  ... loglikelihood=-5.53358982441117\t0.8333333333333334\n",
      " 25:  ... loglikelihood=-5.462594763475646\t0.8333333333333334\n",
      " 26:  ... loglikelihood=-5.394005599373023\t0.8333333333333334\n",
      " 27:  ... loglikelihood=-5.327613825899791\t0.8333333333333334\n",
      " 28:  ... loglikelihood=-5.263239429567834\t0.8333333333333334\n",
      " 29:  ... loglikelihood=-5.2007262935999155\t0.8333333333333334\n",
      " 30:  ... loglikelihood=-5.139938425250175\t0.8333333333333334\n",
      " 31:  ... loglikelihood=-5.080756844166708\t0.8333333333333334\n",
      " 32:  ... loglikelihood=-5.023077004465652\t0.8333333333333334\n",
      " 33:  ... loglikelihood=-4.966806649990853\t0.8333333333333334\n",
      " 34:  ... loglikelihood=-4.91186402292727\t0.8333333333333334\n",
      " 35:  ... loglikelihood=-4.858176362014076\t0.8333333333333334\n",
      " 36:  ... loglikelihood=-4.8056786391705355\t0.8333333333333334\n",
      " 37:  ... loglikelihood=-4.75431249322692\t0.8888888888888888\n",
      " 38:  ... loglikelihood=-4.704025327262282\t0.8888888888888888\n",
      " 39:  ... loglikelihood=-4.654769542256801\t0.8888888888888888\n",
      " 40:  ... loglikelihood=-4.606501884723372\t0.9444444444444444\n",
      " 41:  ... loglikelihood=-4.559182889961656\t0.9444444444444444\n",
      " 42:  ... loglikelihood=-4.512776405786434\t0.9444444444444444\n",
      " 43:  ... loglikelihood=-4.467249184181316\t0.9444444444444444\n",
      " 44:  ... loglikelihood=-4.42257053044379\t0.9444444444444444\n",
      " 45:  ... loglikelihood=-4.378712001115797\t0.9444444444444444\n",
      " 46:  ... loglikelihood=-4.335647143411751\t0.9444444444444444\n",
      " 47:  ... loglikelihood=-4.293351270023711\t0.9444444444444444\n",
      " 48:  ... loglikelihood=-4.251801264148958\t0.9444444444444444\n",
      " 49:  ... loglikelihood=-4.210975410386173\t0.9444444444444444\n",
      " 50:  ... loglikelihood=-4.170853247813543\t0.9444444444444444\n",
      " 51:  ... loglikelihood=-4.131415442119227\t0.9444444444444444\n",
      " 52:  ... loglikelihood=-4.092643674121626\t0.9444444444444444\n",
      " 53:  ... loglikelihood=-4.054520542409325\t0.9444444444444444\n",
      " 54:  ... loglikelihood=-4.0170294781614935\t0.9444444444444444\n",
      " 55:  ... loglikelihood=-3.98015467048911\t0.9444444444444444\n",
      " 56:  ... loglikelihood=-3.943881000874377\t0.9444444444444444\n",
      " 57:  ... loglikelihood=-3.908193985486939\t0.9444444444444444\n",
      " 58:  ... loglikelihood=-3.8730797243268573\t0.9444444444444444\n",
      " 59:  ... loglikelihood=-3.8385248562904697\t0.9444444444444444\n",
      " 60:  ... loglikelihood=-3.8045165193801282\t0.9444444444444444\n",
      " 61:  ... loglikelihood=-3.771042315385821\t0.9444444444444444\n",
      " 62:  ... loglikelihood=-3.738090278458339\t0.9444444444444444\n",
      " 63:  ... loglikelihood=-3.705648847072447\t0.9444444444444444\n",
      " 64:  ... loglikelihood=-3.673706838946228\t0.9444444444444444\n",
      " 65:  ... loglikelihood=-3.642253428541142\t0.9444444444444444\n",
      " 66:  ... loglikelihood=-3.6112781268174943\t0.9444444444444444\n",
      " 67:  ... loglikelihood=-3.580770762963515\t0.9444444444444444\n",
      " 68:  ... loglikelihood=-3.5507214678535712\t0.9444444444444444\n",
      " 69:  ... loglikelihood=-3.5211206590234823\t0.9444444444444444\n",
      " 70:  ... loglikelihood=-3.491959026978825\t0.9444444444444444\n",
      " 71:  ... loglikelihood=-3.4632275226763434\t0.9444444444444444\n",
      " 72:  ... loglikelihood=-3.4349173460395694\t0.9444444444444444\n",
      " 73:  ... loglikelihood=-3.4070199353878117\t0.9444444444444444\n",
      " 74:  ... loglikelihood=-3.3795269576734963\t0.9444444444444444\n",
      " 75:  ... loglikelihood=-3.352430299436392\t0.9444444444444444\n",
      " 76:  ... loglikelihood=-3.3257220583950686\t0.9444444444444444\n",
      " 77:  ... loglikelihood=-3.2993945356062184\t0.9444444444444444\n",
      " 78:  ... loglikelihood=-3.273440228131268\t0.9444444444444444\n",
      " 79:  ... loglikelihood=-3.2478518221574864\t0.9444444444444444\n",
      " 80:  ... loglikelihood=-3.22262218652742\t0.9444444444444444\n",
      " 81:  ... loglikelihood=-3.19774436663629\t0.9444444444444444\n",
      " 82:  ... loglikelihood=-3.173211578662034\t0.9444444444444444\n",
      " 83:  ... loglikelihood=-3.149017204097005\t0.9444444444444444\n",
      " 84:  ... loglikelihood=-3.125154784554155\t0.9444444444444444\n",
      " 85:  ... loglikelihood=-3.1016180168238066\t0.9444444444444444\n",
      " 86:  ... loglikelihood=-3.0784007481599556\t0.9444444444444444\n",
      " 87:  ... loglikelihood=-3.055496971777577\t0.9444444444444444\n",
      " 88:  ... loglikelihood=-3.0329008225444847\t0.9444444444444444\n",
      " 89:  ... loglikelihood=-3.01060657285326\t0.9444444444444444\n",
      " 90:  ... loglikelihood=-2.9886086286603026\t0.9444444444444444\n",
      " 91:  ... loglikelihood=-2.9669015256805475\t0.9444444444444444\n",
      " 92:  ... loglikelihood=-2.945479925727597\t1.0\n",
      " 93:  ... loglikelihood=-2.9243386131900673\t1.0\n",
      " 94:  ... loglikelihood=-2.9034724916359527\t1.0\n",
      " 95:  ... loglikelihood=-2.8828765805375545\t1.0\n",
      " 96:  ... loglikelihood=-2.8625460121103057\t1.0\n",
      " 97:  ... loglikelihood=-2.8424760282593877\t1.0\n",
      " 98:  ... loglikelihood=-2.822661977628643\t1.0\n",
      " 99:  ... loglikelihood=-2.8030993127467205\t1.0\n",
      "100:  ... loglikelihood=-2.7837835872658414\t1.0\n",
      "[We will start with a simple sentence.]\n",
      "[However, is it possible for a sentence to end with a question mark?]\n",
      "[Obviously that is possible!]\n",
      "[Another complication is the use of a number such as 56.32 or ellipses such as ...]\n",
      "[Ellipses may be found ...]\n",
      "[with a sentence!]\n",
      "[Of course, we may also find the use of abbreviations such as Mr.]\n",
      "[Smith or Dr.]\n",
      "[Jones.]\n"
     ]
    }
   ],
   "source": [
    "try (ObjectStream<String> lineStream = new PlainTextByLineStream(\n",
    "                                            () -> new ByteArrayInputStream(trainingSentences.getBytes()), Charset.forName(\"UTF-8\"));\n",
    "    ObjectStream<SentenceSample> sampleStream = new SentenceSampleStream(lineStream)) {\n",
    "    SentenceDetectorFactory sentenceDetectorFactory = \n",
    "    new SentenceDetectorFactory(\"en\", true, null, null);\n",
    "    SentenceModel sentenceModel = SentenceDetectorME.train(\n",
    "        \"en\", sampleStream, sentenceDetectorFactory, TrainingParameters.defaultParams());\n",
    "    \n",
    "    OutputStream modelOutputStream = new BufferedOutputStream(new FileOutputStream(\"../models/modelFile\"));\n",
    "    sentenceModel.serialize(modelOutputStream);\n",
    "    \n",
    "    String text = \"We will start with a simple sentence. However, is it \"\n",
    "    + \"possible for a sentence to end with a question \"\n",
    "    + \"mark? Obviously that is possible! Another \"\n",
    "    + \"complication is the use of a number such as 56.32 \"\n",
    "    + \"or ellipses such as ... Ellipses may be found ... \"\n",
    "    + \"with a sentence! Of course, we may also find the \"\n",
    "    + \"use of abbreviations such as Mr. Smith or \"\n",
    "    + \"Dr. Jones.\";\n",
    " \n",
    "    SentenceDetectorME sentenceDetector = null;\n",
    "    InputStream inputStrean = new FileInputStream(\"../models/modelFile\");\n",
    "    sentenceModel = new SentenceModel(inputStrean);\n",
    "    sentenceDetector = new SentenceDetectorME(sentenceModel);\n",
    "    String sentences[] = sentenceDetector.sentDetect(text);\n",
    "    for (String sentence : sentences) {\n",
    "        System.out.println(\"[\" + sentence + \"]\");\n",
    "    }\n",
    "} catch (FileNotFoundException ex) {\n",
    "    // Handle exceptions\n",
    "    System.out.println(\"No such file exists!\");\n",
    "} catch (IOException ex) {\n",
    "    // Handle exceptions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "14.0.1+7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
